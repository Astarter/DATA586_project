{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python383jvsc74a57bd06daf48744f4ce44b71572c0f8f2a6fb897741990605a7e8599d08bee668bbd40",
   "display_name": "Python 3.8.3 64-bit (conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = \"HDFS.log\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "hdfs = open(file, \"r\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "hdfs_list = hdfs.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#for i in range(1,100):\n",
    "    #print(hdfs_list[i])"
   ]
  },
  {
   "source": [
    "## Total Number of log entries"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "11175629"
      ]
     },
     "metadata": {},
     "execution_count": 72
    }
   ],
   "source": [
    "len(hdfs_list)"
   ]
  },
  {
   "source": [
    "## Unique values for first 6 numerical digits\n",
    "\n",
    "This looks like the dates of the events. Date doesn't seem like it will help with finding anomolies if we have many entries at each date."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_six = []\n",
    "for i in hdfs_list:\n",
    "    match = re.findall('^[0-9]{6}', i)\n",
    "    match = match[0]\n",
    "    first_six.append(match)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "['081109', '081111', '081110']\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "11175629"
      ]
     },
     "metadata": {},
     "execution_count": 82
    }
   ],
   "source": [
    "unique_first_six = list(set(first_six))\n",
    "print(unique_first_six)\n",
    "len(first_six)"
   ]
  },
  {
   "source": [
    "## Unique values for second 6 numerical digits\n",
    "\n",
    "It looks like there are tons of different values here, so this probably won't be significant in determining anomolies and we may not want it include it in our model. "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "second_six = []\n",
    "for i in hdfs_list:\n",
    "    match = re.findall('^[0-9]{6} ([0-9]{6})', i)\n",
    "    match = match[0]\n",
    "    second_six.append(match)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "85053\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "11175629"
      ]
     },
     "metadata": {},
     "execution_count": 87
    }
   ],
   "source": [
    "unique_second_six = list(set(second_six))\n",
    "print(len(unique_second_six))\n",
    "len(second_six)"
   ]
  },
  {
   "source": [
    "## Unique values for third number code\n",
    "\n",
    "There are a lot of different codes here. We will have to count through these to see if there are any that are rare. \n",
    "\n",
    "We may want to convert these to integers."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "third_num = []\n",
    "for i in hdfs_list:\n",
    "    match = re.findall('^[0-9]{6} [0-9]{6} (\\d*) ', i)\n",
    "    match = match[0]\n",
    "    third_num.append(match)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "27799\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "11175629"
      ]
     },
     "metadata": {},
     "execution_count": 91
    }
   ],
   "source": [
    "unique_third_num = list(set(third_num))\n",
    "print(len(unique_third_num))\n",
    "len(third_num)"
   ]
  },
  {
   "source": [
    "## Unique values for first text statement (4 capital letters)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "caps = []\n",
    "for i in hdfs_list:\n",
    "    match = re.findall(' ([A-Z][A-Z][A-Z][A-Z]) ', i)\n",
    "    match = match[0]\n",
    "    caps.append(match)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "['INFO', 'WARN']\n11175629\n"
     ]
    }
   ],
   "source": [
    "unique_caps = list(set(caps))\n",
    "print(unique_caps)\n",
    "print(len(caps))"
   ]
  },
  {
   "source": [
    "## Unique values for \"dfs....:\" statement\n",
    "\n",
    "There are only 9 of these codes. These may be important for finding anomolies.\n",
    "\n",
    "I think we could make a dataframe for each of these 9 codes, then we can find the specific information that are in each one. "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = []\n",
    "for i in hdfs_list:\n",
    "    match = re.findall('dfs\\.\\S*:', i)\n",
    "    match = match[0]\n",
    "    dfs.append(match)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "9\n['dfs.DataBlockScanner:', 'dfs.FSDataset:', 'dfs.DataNode$DataXceiver:', 'dfs.DataNode:', 'dfs.FSNamesystem:', 'dfs.DataNode$BlockReceiver:', 'dfs.PendingReplicationBlocks$PendingReplicationMonitor:', 'dfs.DataNode$DataTransfer:', 'dfs.DataNode$PacketResponder:']\n11175629\n"
     ]
    }
   ],
   "source": [
    "unique_dfs = list(set(dfs))\n",
    "print(len(unique_dfs))\n",
    "print(unique_dfs)\n",
    "print(len(dfs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "hdfs.close()"
   ]
  },
  {
   "source": [
    "## Labels information\n",
    "\n",
    "It looks like the blocks are labelled, and each log entry contains at least one block. It looks like we will have to somehow find out which blocks are anomolies and which ones are normal. \n",
    "\n",
    "When do we determine if a block is normal or an anomoly?\n",
    "\n",
    "Blocks must be in more than one event (there are a lot more events than anomoly labels), so are we finding events that are anomolies? Or blocks that are anomolies?"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = pd.read_csv(\"anomaly_label.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                    BlockId    Label\n",
       "0  blk_-1608999687919862906   Normal\n",
       "1   blk_7503483334202473044   Normal\n",
       "2  blk_-3544583377289625738  Anomaly\n",
       "3  blk_-9073992586687739851   Normal\n",
       "4   blk_7854771516489510256   Normal"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>BlockId</th>\n      <th>Label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>blk_-1608999687919862906</td>\n      <td>Normal</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>blk_7503483334202473044</td>\n      <td>Normal</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>blk_-3544583377289625738</td>\n      <td>Anomaly</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>blk_-9073992586687739851</td>\n      <td>Normal</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>blk_7854771516489510256</td>\n      <td>Normal</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 99
    }
   ],
   "source": [
    "labels.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 575061 entries, 0 to 575060\nData columns (total 2 columns):\n #   Column   Non-Null Count   Dtype \n---  ------   --------------   ----- \n 0   BlockId  575061 non-null  object\n 1   Label    575061 non-null  object\ndtypes: object(2)\nmemory usage: 8.8+ MB\n"
     ]
    }
   ],
   "source": [
    "labels.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}