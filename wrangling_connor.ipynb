{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python383jvsc74a57bd06daf48744f4ce44b71572c0f8f2a6fb897741990605a7e8599d08bee668bbd40",
   "display_name": "Python 3.8.3 64-bit (conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = \"HDFS.log\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "hdfs = open(file, \"r\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "hdfs_list = hdfs.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#for i in range(1,100):\n",
    "    #print(hdfs_list[i])"
   ]
  },
  {
   "source": [
    "## Total Number of log entries"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "11175629"
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "len(hdfs_list)"
   ]
  },
  {
   "source": [
    "Here is an example of a log event from the HDFS log file and this shows what the event contains.\n",
    "\n",
    "![log event breakdown](event_breakdown.png)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Unique values for first 6 numerical digits (date)\n",
    "\n",
    "This looks like the dates of the events. Date doesn't seem like it will help with finding anomolies if we have many entries at each date."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_six = []\n",
    "for i in hdfs_list:\n",
    "    match = re.findall('^[0-9]{6}', i)\n",
    "    match = match[0]\n",
    "    first_six.append(match)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "['081109', '081111', '081110']\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "11175629"
      ]
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "unique_first_six = list(set(first_six))\n",
    "print(unique_first_six)\n",
    "len(first_six)"
   ]
  },
  {
   "source": [
    "## Unique values for second 6 numerical digits (time?)\n",
    "\n",
    "It looks like there are tons of different values here, so this probably won't be significant in determining anomolies and we may not want it include it in our model. "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "second_six = []\n",
    "for i in hdfs_list:\n",
    "    match = re.findall('^[0-9]{6} ([0-9]{6})', i)\n",
    "    match = match[0]\n",
    "    second_six.append(match)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "85053\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "11175629"
      ]
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "source": [
    "unique_second_six = list(set(second_six))\n",
    "print(len(unique_second_six))\n",
    "len(second_six)"
   ]
  },
  {
   "source": [
    "## Unique values for third number (code)\n",
    "\n",
    "There are a lot of different codes here. We will have to count through these to see if there are any that are rare. \n",
    "\n",
    "We may want to convert these to integers."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "third_num = []\n",
    "for i in hdfs_list:\n",
    "    match = re.findall('^[0-9]{6} [0-9]{6} (\\d*) ', i)\n",
    "    match = match[0]\n",
    "    third_num.append(match)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "27799\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "11175629"
      ]
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "source": [
    "unique_third_num = list(set(third_num))\n",
    "print(len(unique_third_num))\n",
    "len(third_num)"
   ]
  },
  {
   "source": [
    "## Unique values for first text statement (message)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "caps = []\n",
    "for i in hdfs_list:\n",
    "    match = re.findall(' ([A-Z][A-Z][A-Z][A-Z]) ', i)\n",
    "    match = match[0]\n",
    "    caps.append(match)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "['INFO', 'WARN']\n11175629\n"
     ]
    }
   ],
   "source": [
    "unique_caps = list(set(caps))\n",
    "print(unique_caps)\n",
    "print(len(caps))"
   ]
  },
  {
   "source": [
    "## Unique values for \"dfs....:\" statement (event type)\n",
    "\n",
    "There are only 9 of these codes. These may be important for finding anomolies.\n",
    "\n",
    "I think we could make a dataframe for each of these 9 codes, then we can find the specific information that are in each one. "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = []\n",
    "for i in hdfs_list:\n",
    "    match = re.findall('dfs\\.\\S*:', i)\n",
    "    match = match[0]\n",
    "    dfs.append(match)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "9\n['dfs.PendingReplicationBlocks$PendingReplicationMonitor:', 'dfs.DataNode$BlockReceiver:', 'dfs.FSDataset:', 'dfs.DataBlockScanner:', 'dfs.DataNode:', 'dfs.FSNamesystem:', 'dfs.DataNode$PacketResponder:', 'dfs.DataNode$DataXceiver:', 'dfs.DataNode$DataTransfer:']\n11175629\n"
     ]
    }
   ],
   "source": [
    "unique_dfs = list(set(dfs))\n",
    "print(len(unique_dfs))\n",
    "print(unique_dfs)\n",
    "print(len(dfs))"
   ]
  },
  {
   "source": [
    "## Labels information\n",
    "\n",
    "It looks like the blocks are labelled, and each log entry contains at least one block. It looks like we will have to somehow find out which blocks are anomolies and which ones are normal. \n",
    "\n",
    "When do we determine if a block is normal or an anomoly?\n",
    "\n",
    "Blocks must be in more than one event (there are a lot more events than anomoly labels), so are we finding events that are anomolies? Or blocks that are anomolies?"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = pd.read_csv(\"anomaly_label.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                    BlockId    Label\n",
       "0  blk_-1608999687919862906   Normal\n",
       "1   blk_7503483334202473044   Normal\n",
       "2  blk_-3544583377289625738  Anomaly\n",
       "3  blk_-9073992586687739851   Normal\n",
       "4   blk_7854771516489510256   Normal"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>BlockId</th>\n      <th>Label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>blk_-1608999687919862906</td>\n      <td>Normal</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>blk_7503483334202473044</td>\n      <td>Normal</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>blk_-3544583377289625738</td>\n      <td>Anomaly</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>blk_-9073992586687739851</td>\n      <td>Normal</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>blk_7854771516489510256</td>\n      <td>Normal</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 18
    }
   ],
   "source": [
    "labels.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 575061 entries, 0 to 575060\nData columns (total 2 columns):\n #   Column   Non-Null Count   Dtype \n---  ------   --------------   ----- \n 0   BlockId  575061 non-null  object\n 1   Label    575061 non-null  object\ndtypes: object(2)\nmemory usage: 8.8+ MB\n"
     ]
    }
   ],
   "source": [
    "labels.info()"
   ]
  },
  {
   "source": [
    "## Finding the events with more than one block named in it:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "This cells shows how many events mention more than one block in it. We can see that there are 1402056 events that mention more than one block. This doesn't check if the multiple blocks mentioned are identical to each other or not. "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "multiple_blocks_test = []\n",
    "for i in hdfs_list:\n",
    "    match = re.findall('blk_\\S*', i)\n",
    "    if len(match) > 1:\n",
    "        multiple_blocks_test.append(match)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "1402056"
      ]
     },
     "metadata": {},
     "execution_count": 57
    }
   ],
   "source": [
    "len(multiple_blocks_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[['blk_-6899869435641005946', 'blk_-6899869435641005946'],\n",
       " ['blk_-8191677345482862686', 'blk_-8191677345482862686'],\n",
       " ['blk_-919439116365725304', 'blk_-919439116365725304'],\n",
       " ['blk_3557914126063085372', 'blk_3557914126063085372'],\n",
       " ['blk_3584224065406961324', 'blk_3584224065406961324'],\n",
       " ['blk_349284099419601276', 'blk_349284099419601276'],\n",
       " ['blk_-7057732666118938934', 'blk_-7057732666118938934'],\n",
       " ['blk_-5410886886439711883', 'blk_-5410886886439711883'],\n",
       " ['blk_-6739860488313725269', 'blk_-6739860488313725269']]"
      ]
     },
     "metadata": {},
     "execution_count": 56
    }
   ],
   "source": [
    "multiple_blocks_test[1:10]"
   ]
  },
  {
   "source": [
    "We can see from the cell above that the when multiple blocks are mentioned, it looks like they are duplicates. \n",
    "\n",
    "In the cell below we will check how many events that mention more than one block actually mention different unique blocks. We can see that there are no lines that mention more than one unique block, so we can focus on only the first block that is mentioned in each event (since any additional blocks mentioned are the same as the first one)."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "multiple_blocks = []\n",
    "for i in hdfs_list:\n",
    "    match = re.findall('blk_\\S*', i)\n",
    "    if len(match) > 1:\n",
    "        holder = 0\n",
    "        first = match[0]\n",
    "        for x in match:\n",
    "            if x != first:\n",
    "                holder = 1\n",
    "        if holder == 1:\n",
    "            multiple_blocks.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "metadata": {},
     "execution_count": 59
    }
   ],
   "source": [
    "len(multiple_blocks)"
   ]
  },
  {
   "source": [
    "## Determining the number of unique blocks mentioned in this entire HDFS file (block id's):"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "blocks = []\n",
    "for i in hdfs_list:\n",
    "    match = re.findall('blk_\\S*', i)\n",
    "    match = match[0]\n",
    "    blocks.append(match)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "11175629\n580406\n575061\n"
     ]
    }
   ],
   "source": [
    "unique_blocks = list(set(blocks))\n",
    "print(len(blocks))\n",
    "print(len(unique_blocks))\n",
    "print(len(labels))"
   ]
  },
  {
   "source": [
    "We can see from the cell above that the number of unique blocks in the HDFS file is within about 5000 of the number of labelled blocks in the `anomaly_label.csv` file."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "hdfs.close()"
   ]
  }
 ]
}